import streamlit as st
import os
import time
import json
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
from qwen_llm import process_text_with_qwen, extract_qa_pairs_from_llm_result, split_text_to_qa_pairs

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="éŸ³é¢‘æ–‡æœ¬å¤„ç†ç³»ç»Ÿ",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .tab-content {
        padding: 2rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
asr_model = None
model_loaded = False

# åˆå§‹åŒ–ASRæ¨¡å‹
@st.cache_resource
def initialize_asr_model():
    """åˆå§‹åŒ–ASRæ¨¡å‹ï¼ˆåº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
    import torch
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    try:
        model = AutoModel(
            model="iic/SenseVoiceSmall",
            vad_model="fsmn-vad",
            vad_kwargs={
                "max_single_segment_time": 60000,
                "min_single_segment_time": 1000,
                "max_segment_length": 100000,
            },
            device=device,
            disable_update=True,  # ç¦æ­¢è”ç½‘æ£€æŸ¥å’Œä¸‹è½½
        )
        return model, device, None
    except Exception as e:
        return None, device, str(e)

def get_asr_model():
    """è·å–ASRæ¨¡å‹å®ä¾‹"""
    if 'asr_model' not in st.session_state:
        model, device, err = initialize_asr_model()
        st.session_state['asr_model'] = model
        st.session_state['asr_device'] = device
        st.session_state['asr_error'] = err
    return st.session_state.get('asr_model'), st.session_state.get('asr_device'), st.session_state.get('asr_error')

def asr_tab():
    """ASRéŸ³é¢‘è½¬å†™åŠŸèƒ½"""
    st.markdown('<h2 class="main-header">ğŸ¤ éŸ³é¢‘è½¬å†™ (ASR)</h2>', unsafe_allow_html=True)
    model, device, err = get_asr_model()
    # åªåœ¨é¦–æ¬¡åŠ è½½æˆåŠŸæ—¶å¼¹å‡ºtoast
    if err:
        st.error(f"âŒ ASRæ¨¡å‹åŠ è½½å¤±è´¥: {err}")
        return
    if not model:
        st.info("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–ASRæ¨¡å‹ï¼Œè¯·ç¨å€™...")
        return
    # åªå¼¹ä¸€æ¬¡toast
    if not st.session_state.get("asr_model_loaded_toast", False):
        if hasattr(st, "toast"):
            st.toast(f"âœ… ASRæ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {device}", icon="âœ…")
        else:
            st.success(f"âœ… ASRæ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {device}")
        st.session_state["asr_model_loaded_toast"] = True
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ ASRé…ç½®")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        st.markdown("### ğŸ“‹ æ¨¡å‹ä¿¡æ¯")
        st.info(f"è®¾å¤‡: {'GPU' if 'cuda' in device else 'CPU'}")
        st.info("æ¨¡å‹: SenseVoiceSmall")
        
        # å‚æ•°é…ç½®
        st.markdown("### âš™ï¸ å‚æ•°é…ç½®")
        batch_size = st.slider("æ‰¹å¤„ç†å¤§å°", min_value=60, max_value=200, value=120, step=20)
        merge_length = st.slider("åˆå¹¶é•¿åº¦(ç§’)", min_value=10, max_value=60, value=30, step=5)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š å¤„ç†ç»Ÿè®¡")
        # ç»Ÿè®¡æ¯æ¬¡éƒ½ä» session_state è¯»å–ï¼Œä¿è¯è‡ªåŠ¨åˆ·æ–°
        stats = st.session_state.get('asr_stats', {})
        st.metric("å¤„ç†æ—¶é—´", f"{stats.get('time', 0):.2f}ç§’")
        st.metric("æ–‡æœ¬é•¿åº¦", f"{stats.get('text_length', 0)}å­—ç¬¦")
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ")
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            type=['wav', 'mp3', 'm4a', 'flac', 'aac'],
            help="æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼Œå»ºè®®æ–‡ä»¶å¤§å°ä¸è¶…è¿‡100MB"
        )
        
        # å¤„ç†æŒ‰é’®
        st.markdown("---")
        if st.button("ğŸš€ å¼€å§‹è½¬å†™", type="primary", use_container_width=True):
            if uploaded_file:
                process_audio(uploaded_file, batch_size, merge_length)
            else:
                st.warning("è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
    
    with col2:
        st.subheader("ğŸ“ è½¬å†™ç»“æœ")
        
        # æ˜¾ç¤ºè½¬å†™ç»“æœ
        if 'transcribed_text' in st.session_state:
            text = st.session_state.transcribed_text
            
            # æ–‡æœ¬æ˜¾ç¤º
            st.text_area(
                "è½¬å†™æ–‡æœ¬",
                value=text,
                height=400,
                help="è½¬å†™ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ"
            )
            
            # æ“ä½œæŒ‰é’®
            col_btn1, col_btn2, col_btn3 = st.columns(3)
            
            with col_btn1:
                if st.button("ğŸ“‹ å¤åˆ¶æ–‡æœ¬", use_container_width=True):
                    st.write("æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
                    st.session_state['copied'] = True
            
            with col_btn2:
                # ä¸‹è½½ä¸ºtxt
                st.download_button(
                    label="ğŸ’¾ ä¸‹è½½ä¸ºTXT",
                    data=text,
                    file_name="transcription.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            with col_btn3:
                if st.button("ğŸ”„ æ¸…ç©ºç»“æœ", use_container_width=True):
                    clear_results()
            
            # æ˜¾ç¤ºå¤åˆ¶æˆåŠŸæ¶ˆæ¯
            if st.session_state.get('copied', False):
                st.success("âœ… æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
                st.session_state['copied'] = False
        
        else:
            st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶å¼€å§‹è½¬å†™")

def process_audio(uploaded_file, batch_size, merge_length):
    """å¤„ç†éŸ³é¢‘æ–‡ä»¶"""
    try:
        model, device, err = get_asr_model()
        if err:
            st.error(f"âŒ ASRæ¨¡å‹åŠ è½½å¤±è´¥: {err}")
            return
        if not model:
            st.error("ASRæ¨¡å‹æœªåŠ è½½")
            return
        
        # ç¡®å®šéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        audio_path = None
        if uploaded_file:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            temp_dir = "temp_uploads"
            os.makedirs(temp_dir, exist_ok=True)
            audio_path = os.path.join(temp_dir, uploaded_file.name)
            with open(audio_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
        else:
            st.error("æ— æ•ˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
            return
        
        # å¼€å§‹è½¬å†™
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("ğŸµ æ­£åœ¨è½¬å†™éŸ³é¢‘...")
        progress_bar.progress(25)
        
        start_time = time.time()
        
        # æ‰§è¡Œè½¬å†™
        res = model.generate(
            input=audio_path,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=batch_size,
            merge_vad=True,
            merge_length_s=merge_length,
        )
        
        progress_bar.progress(75)
        status_text.text("ğŸ“ æ­£åœ¨åå¤„ç†æ–‡æœ¬...")
        
        # åå¤„ç†
        transcribed_text = rich_transcription_postprocess(res[0]["text"])
        
        progress_bar.progress(100)
        status_text.text("âœ… è½¬å†™å®Œæˆ!")
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœåˆ°session state
        st.session_state.transcribed_text = transcribed_text
        st.session_state.asr_stats = {
            'time': processing_time,
            'text_length': len(transcribed_text),
            'file_name': uploaded_file.name
        }
        
        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
        st.success(f"ğŸ‰ è½¬å†™å®Œæˆï¼è€—æ—¶ {processing_time:.2f} ç§’")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if uploaded_file and os.path.exists(audio_path):
            os.remove(audio_path)
        # å…¼å®¹æ–°æ—§Streamlitçš„è‡ªåŠ¨åˆ·æ–°
        try:
            st.rerun()
        except AttributeError:
            try:
                st.experimental_rerun()
            except AttributeError:
                pass  # ä½ç‰ˆæœ¬ä¸æ”¯æŒè‡ªåŠ¨åˆ·æ–°
        
    except Exception as e:
        st.error(f"âŒ è½¬å†™å¤±è´¥: {str(e)}")
        st.exception(e)

def save_transcription_result(text):
    """ä¿å­˜è½¬å†™ç»“æœ"""
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"transcription_{timestamp}.txt"
        
        with open(filename, "w", encoding="utf-8") as f:
            f.write(text)
        
        st.success(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        # åŒæ—¶ä¿å­˜JSONæ ¼å¼
        json_filename = f"transcription_{timestamp}.json"
        result_data = {
            "timestamp": timestamp,
            "text": text,
            "text_length": len(text),
            "stats": st.session_state.get('asr_stats', {})
        }
        
        with open(json_filename, "w", encoding="utf-8") as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}")

def clear_results():
    """æ¸…ç©ºç»“æœ"""
    if 'transcribed_text' in st.session_state:
        del st.session_state.transcribed_text
    if 'asr_stats' in st.session_state:
        del st.session_state.asr_stats
    st.rerun()

def qa_split_tab():
    """é—®ç­”å¯¹æ‹†åˆ†åŠŸèƒ½"""
    st.markdown('<h2 class="main-header">âœ‚ï¸ é—®ç­”å¯¹æ‹†åˆ†</h2>', unsafe_allow_html=True)
    st.info("ğŸ”§ æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

def qa_smooth_tab():
    """é—®ç­”å¯¹å¹³é¡ºåŠŸèƒ½"""
    st.markdown('<h2 class="main-header">âœ¨ é—®ç­”å¯¹å¹³é¡º</h2>', unsafe_allow_html=True)
    st.info("ğŸ”§ æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

def structured_output_tab():
    """ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½"""
    st.markdown('<h2 class="main-header">ğŸ“Š ç»“æ„åŒ–è¾“å‡º</h2>', unsafe_allow_html=True)
    st.info("ğŸ”§ æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

def main():
    """ä¸»å‡½æ•°"""
    st.markdown('<h1 class="main-header">ğŸ¤ éŸ³é¢‘æ–‡æœ¬å¤„ç†ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    # åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹
    get_asr_model()
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ¤ ASRè½¬å†™", 
        "âœ‚ï¸ é—®ç­”æ‹†åˆ†", 
        "âœ¨ é—®ç­”å¹³é¡º", 
        "ğŸ“Š ç»“æ„åŒ–è¾“å‡º"
    ])
    
    # æ ‡ç­¾é¡µå†…å®¹
    with tab1:
        asr_tab()
    
    with tab2:
        qa_split_tab()
    
    with tab3:
        qa_smooth_tab()
    
    with tab4:
        structured_output_tab()

if __name__ == "__main__":
    main()
